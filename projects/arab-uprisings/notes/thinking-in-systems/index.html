<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Notes | Thinking in Systems &middot; Elisabeth Gray
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/lanyon.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- meta robots -->
  
</head>

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-59093032-1', 'auto');
  ga('send', 'pageview');
</script>


  <body class="theme-base-22">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
    
    
    
    
    
    
    
    
    
    
    <a class="sidebar-nav-item" href="/archive/">Blog Posts</a>
    
    
    
    
    
    
    
    
    
    <a class="sidebar-nav-item" href="/cv/">Curriculum Vitae</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <a class="sidebar-nav-item" href="/papers/">Academic Papers</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    <a class="sidebar-nav-item" href="/projects/">Academic Projects</a>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    

    <a class="sidebar-nav-item" href="https://github.com/elcgray">GitHub</a>

    <a class="sidebar-nav-item" href="https://twitter.com/elcgray" class="twitter-follow-button" data-show-count="false">Twitter</a>

  <div class="sidebar-item">
    <p>
      &copy; 2015. All rights reserved.<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" /></a>

    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <label for="sidebar-checkbox" class="sidebar-toggle"></label>

          <h3 class="masthead-title">
            <a href="/" title="Home">Elisabeth Gray</a>
            <small>a repository of personal and academic work</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <body class="theme-base-22">

<div class="page">
  <h1 class="page-title">Notes | Thinking in Systems</h1>
  <h4><span id="meadows">Meadows, D. H., &amp; Wright, D. (2008). <i>Thinking in Systems: A Primer</i> (Kindle). Chelsea Green Publishing.</span></h4>

<ul>
<li>unsustainable patterns could, if unchecked, wreak havoc across the globe.<br /> loc. 126</li>
<li>Systems, big or small, can behave in similar ways, and understanding those ways is perhaps our best hope for making lasting change on many levels.<br /> loc. 133</li>
<li>Once you start to see the events of the day as parts of trends, and those trends as symptoms of underlying system structure, you will be able to consider new ways to manage and new ways to live in a world of complex systems.<br /> loc. 160</li>
<li>The hands that manipulate it suppress or release some behavior that is latent within the structure of the spring.<br /> loc. 189</li>
<li>A system is a set of things—people, cells, molecules, or whatever—interconnected in such a way that they produce their own pattern of behavior over time.<br /> loc. 195</li>
<li>Psychologically and politically we would much rather assume that the cause of a problem is “out there,” rather than “in here.”<br /> loc. 239</li>
<li>Because they are embedded in larger systems, however, some of our “solutions” have created further problems.<br /> loc. 243</li>
<li>They will yield only as we reclaim our intuition, stop casting blame, see the system as the source of its own problems, and find the courage and wisdom to restructure it.<br /> loc. 249</li>
<li>Words and sentences must, by necessity, come only one at a time in linear, logical order. Systems happen all at once. They are connected not just in one direction, but in many directions simultaneously.<br /> loc. 257</li>
<li>the basic operating unit of a system: the feedback loop.<br /> loc. 263</li>
<li>structures that produce characteristic behaviors “archetypes.”<br /> loc. 279</li>
<li>The behavior of a system cannot be known just by knowing the elements of which the system is made.<br /> loc. 316</li>
<li>I have yet to see any problem, however complicated, which, when looked at in the right way, did not become still more complicated. —POUL ANDERSON<br /> loc. 322</li>
<li>A system* is an interconnected set of elements that is coherently organized in a way that achieves something. If you look at that definition closely for a minute, you can see that a system must consist of three kinds of things: elements, interconnections, and a function or purpose.<br /> loc. 327</li>
<li>Systems can be embedded in systems, which are embedded in yet other systems.<br /> loc. 338</li>
<li>A system is more than the sum of its parts. It may exhibit adaptive, dynamic, goal-seeking, self-preserving, and sometimes evolutionary behavior.<br /> loc. 346</li>
<li>You think that because you understand “one” that you must therefore understand “two” because one and one make two. But you forget that you must also understand “and.” —Sufi teaching story<br /> loc. 353</li>
<li>interconnections, the relationships that hold the elements together.<br /> loc. 372</li>
<li>Many of the interconnections in systems operate through the flow of information. Information holds systems together and plays a great role in determining how they operate.<br /> loc. 384</li>
<li>The best way to deduce the system’s purpose is to watch for a while to see how the system behaves.<br /> loc. 395</li>
<li>Purposes are deduced from behavior, not from rhetoric or stated goals.<br /> loc. 399</li>
<li>An important function of almost every system is to ensure its own perpetuation.<br /> loc. 405</li>
<li>Keeping sub-purposes and overall system purposes in harmony is an essential function of successful systems.<br /> loc. 422</li>
<li>A system generally goes on being itself, changing only slowly if at all, even with complete substitutions of its elements—as long as its interconnections and purposes remain intact.<br /> loc. 430</li>
<li>The least obvious part of the system, its function or purpose, is often the most crucial determinant of the system’s behavior.<br /> loc. 432</li>
<li>A change in purpose changes a system profoundly, even if every element and interconnection remains the same.<br /> loc. 443</li>
<li>Storing information means increasing the complexity of the mechanism. —Ramon Margalef<br /> loc. 457</li>
<li>A stock is the foundation of any system. Stocks are the elements of the system that you can see, feel, count, or measure at any given time.<br /> loc. 460</li>
<li>A stock is the memory of the history of changing flows within the system.<br /> loc. 465</li>
<li>Stocks change over time through the actions of a flow.<br /> loc. 466</li>
<li>A stock, then, is the present memory of the history of changing flows within the system.<br /> loc. 467</li>
<li>If you understand the dynamics of stocks and flows—their behavior over time—you understand a good deal about the behavior of complex systems.<br /> loc. 488</li>
<li>A stock takes time to change, because flows take time to flow. That’s a vital point, a key to understanding why systems behave as they do. Stocks usually change slowly. They can act as delays, lags, buffers, ballast, and sources of momentum in a system. Stocks, especially large ones, respond to change, even sudden change, only by gradual filling or emptying.<br /> loc. 539</li>
<li>stocks act as delays or buffers or shock absorbers in systems.<br /> loc. 543</li>
<li>The time lags imposed by stocks allow room to maneuver, to experiment, and to revise policies that aren’t working.<br /> loc. 555</li>
<li>Stocks allow inflows and outflows to be decoupled and to be independent and temporarily out of balance with each other.<br /> loc. 562</li>
<li>Everything we do as individuals, as an industry, or as a society is done in the context of an information-feedback system.<br /> loc. 585</li>
<li>A feedback loop is formed when changes in a stock affect the flows into or out of that same stock.<br /> loc. 592</li>
<li>A feedback loop is a closed chain of causal connections from a stock, through a set of decisions or rules or physical laws or actions that are dependent on the level of the stock, and back again through a flow to change the stock.<br /> loc. 613</li>
<li>feedback loops often can operate in two directions.<br /> loc. 628</li>
<li>stabilizing, goal-seeking, regulating loop is called a balancing feedback loop,<br /> loc. 639</li>
<li>the “homing” behavior of a balancing feedback loop.<br /> loc. 651</li>
<li>The change is faster at first, and then slower, as the discrepancy between the stock and the goal decreases.<br /> loc. 653</li>
<li>Balancing feedback loops are equilibrating or goal-seeking structures in systems and are both sources of stability and sources of resistance to change.<br /> loc. 660</li>
<li>Feedbacks—the interconnections, the information part of the system—can fail for many reasons.<br /> loc. 663</li>
<li>The second kind of feedback loop is amplifying, reinforcing, self-multiplying, snowballing—a vicious or virtuous circle that can cause healthy growth or runaway destruction. It is called a reinforcing feedback loop,<br /> loc. 676</li>
<li>A reinforcing feedback loop enhances whatever direction of change is imposed on it.<br /> loc. 678</li>
<li>Reinforcing loops are found wherever a system element has the ability to reproduce itself or to grow as a constant fraction of itself.<br /> loc. 690</li>
<li>Reinforcing feedback loops are self-enhancing, leading to exponential growth or to runaway collapses over time. They are found whenever a stock has the capacity to reinforce or reproduce itself.<br /> loc. 703</li>
<li>The time it takes for an exponentially growing stock to double in size, the “doubling time,” equals approximately 70 divided by the growth rate (expressed as a percentage).<br /> loc. 720</li>
<li><strong>The concept of feedback opens up the idea that a system can cause its own behavior.</strong> <br /> loc. 729</li>
<li>The information delivered by a feedback loop can only affect future behavior; it can’t deliver the information, and so can’t have an impact fast enough to correct behavior that drove the current feedback.<br /> loc. 801</li>
<li>The information delivered by a feedback loop—even nonphysical feedback—can only affect future behavior; it can’t deliver a signal fast enough to correct behavior that drove the current feedback. Even nonphysical information takes time to feedback into the system.<br /> loc. 805</li>
<li>a flow can’t react instantly to a flow. It can react only to a change in a stock, and only after a slight delay to register the incoming information.<br /> loc. 809</li>
<li>A stock-maintaining balancing feedback loop must have its goal set appropriately to compensate for draining or inflowing processes that affect that stock. Otherwise, the feedback process will fall short of or exceed the target for the stock.<br /> loc. 820</li>
<li>Every balancing feedback loop has its breakdown point, where other loops pull the stock away from its goal more strongly than it can pull back.<br /> loc. 826</li>
<li>Because systems often have several competing feedback loops operating simultaneously, those loops that dominate the system will determine the behavior.<br /> loc. 877</li>
<li>Complex behaviors of systems often arise as the relative strengths of feedback loops shift, causing first one loop and then another to dominate behavior.<br /> loc. 884</li>
<li>System dynamics models explore possible futures and ask “what if” questions.<br /> loc. 921</li>
<li>Model utility depends not on whether its driving scenarios are realistic (since no one can know that for sure), but on whether it responds with a realistic pattern of behavior.<br /> loc. 930</li>
<li>Systems with similar feedback structures produce similar dynamic behaviors.<br /> loc. 985</li>
<li>A delay in a balancing feedback loop makes a system likely to oscillate.<br /> loc. 1040</li>
<li>Delays are pervasive in systems, and they are strong determinants of behavior. Changing the length of a delay may (or may not, depending on the type of delay and the relative lengths of other delays) make a large change in the behavior of a system.<br /> loc. 1069</li>
<li>We can’t begin to understand the dynamic behavior of systems unless we know where and how long the delays are. And we are aware that some delays can be powerful policy levers. Lengthening or shortening them can produce major changes in the behavior of systems.<br /> loc. 1076</li>
<li>any physical, growing system is going to run into some kind of constraint, sooner or later.<br /> loc. 1103</li>
<li>Growth in a constrained environment is very common, so common that systems thinkers call it the “limits-to-growth” archetype.<br /> loc. 1105</li>
<li>no real physical system can grow forever.<br /> loc. 1110</li>
<li>In physical, exponentially growing systems, there must be at least one reinforcing loop driving the growth and at least one balancing loop constraining the growth, because no physical system can grow forever in a finite environment.<br /> loc. 1113</li>
<li>Whether the constraining balancing loops originate from a renewable or nonrenewable resource makes some difference, not in whether growth can continue forever, but in how growth is likely to end.<br /> loc. 1122</li>
<li>A quantity growing exponentially toward a constraint or limit reaches that limit in a surprisingly short time.<br /> loc. 1165</li>
<li><strong>The trick, as with all the behavioral possibilities of complex systems, is to recognize what structures contain which latent behaviors, and what conditions release those behaviors—and, where possible, to arrange the structures and conditions to reduce the probability of destructive behaviors and to encourage the possibility of beneficial ones.</strong> <br /> loc. 1294 <strong>note:</strong> nbd</li>
<li>Resilience is a measure of a system’s ability to survive and persist within a variable environment. The opposite of resilience is brittleness or rigidity.<br /> loc. 1323</li>
<li>There are always limits to resilience.<br /> loc. 1336</li>
<li>Static stability is something you can see; it’s measured by variation in the condition of a system week by week or year by year. Resilience is something that may be very hard to see, unless you exceed its limits, overwhelm and damage the balancing loops, and the system structure breaks down. Because resilience may not be obvious without a whole-system view, people often sacrifice resilience for stability, or for productivity, or for some other more immediately recognizable system property.<br /> loc. 1345</li>
<li><strong>Large organizations of all kinds, from corporations to governments, lose their resilience simply because the feedback mechanisms by which they sense and respond to their environment have to travel through too many layers of delay and distortion.</strong> <br /> loc. 1362</li>
<li><strong>Systems need to be managed not only for productivity or stability, they also need to be managed for resilience—the ability to recover from perturbation, the ability to restore or repair themselves.</strong> <br /> loc. 1370</li>
<li>Awareness of resilience enables one to see many ways to preserve or enhance a system’s own restorative powers.<br /> loc. 1373</li>
<li><strong>This capacity of a system to make its own structure more complex is called self-organization.</strong> <br /> loc. 1387</li>
<li><strong>Like resilience, self-organization is often sacrificed for purposes of short-term productivity and stability.</strong> <br /> loc. 1394</li>
<li>Self-organization produces heterogeneity and unpredictability. It is likely come up with whole new structures, whole new ways of doing things. It requires freedom and experimentation, and a certain amount of disorder.<br /> loc. 1397</li>
<li>These conditions that encourage self-organization often can be scary for individuals and threatening to power structures.<br /> loc. 1398</li>
<li><strong>self-organization is such a basic property of living systems that even the most overbearing power structure can never fully kill it, although in the name of law and order, self-organization can be suppressed for long, barren, cruel, boring periods.</strong> <br /> loc. 1402 <strong>note:</strong> social media as example?</li>
<li>Computers were used to model mechanistic, “deterministic” systems, not evolutionary ones, because it was suspected, without much thought, that evolutionary systems were simply not understandable.<br /> loc. 1405</li>
<li><strong>Out of simple rules of self-organization can grow enormous, diversifying crystals of technology, physical structures, organizations, and cultures.</strong> <br /> loc. 1428</li>
<li><strong>Systems often have the property of self-organization—the ability to structure themselves, to create new structure, to learn, diversify, and complexify. Even complex forms of self-organization may arise from relatively simple organizing rules—or may not.</strong> <br /> loc. 1430 <strong>note:</strong> this is the basis of my interest</li>
<li>In the process of creating new structures and increasing complexity, one thing that a self-organizing system often generates is hierarchy.<br /> loc. 1442</li>
<li>If subsystems can largely take care of themselves, regulate themselves, maintain themselves, and yet serve the needs of the larger system, while the larger system coordinates and enhances the functioning of the subsystems, a stable, resilient, and efficient structure results.<br /> loc. 1449</li>
<li>Hierarchies are brilliant systems inventions, not only because they give a system stability and resilience, but also because they reduce the amount of information that any part of the system has to keep track of.<br /> loc. 1467</li>
<li>In hierarchical systems relationships within each subsystem are denser and stronger than relationships between subsystems.<br /> loc. 1469</li>
<li>one should not lose sight of the important relationships that each subsystem to the others and to the higher levels of the hierarchy,<br /> loc. 1478</li>
<li>What you need to think about may change over time, as self-organizing systems evolve new degrees of hierarchy and integration.<br /> loc. 1484</li>
<li><strong>Hierarchies evolve from the lowest level up—from the pieces to the whole, from cell to organ to organism, from individual to team, from actual production to management of production.</strong> <br /> loc. 1491</li>
<li>The original purpose of a hierarchy is always to help its originating subsystems do their jobs better.<br /> loc. 1493</li>
<li>When a subsystem’s goals dominate at the expense of the total system’s goals, the resulting behavior is called suboptimization.<br /> loc. 1500</li>
<li>Economic examples of overcontrol from the top, from companies to nations, are the causes of some of the great catastrophes of history, all of which are by no means behind us.<br /> loc. 1505</li>
<li><strong>To be a highly functional system, hierarchy must balance the welfare, freedoms, and responsibilities of the subsystems and total system—there must be enough central control to achieve coordination toward the large system goal, and enough autonomy to keep all subsystems flourishing, functioning, and self-organizing.</strong> <br /> loc. 1506</li>
<li>Resilience, self-organization, and hierarchy are three of the reasons dynamic systems can work so well.<br /> loc. 1509</li>
<li>Hierarchical systems evolve from the bottom up. The purpose of the upper layers of the hierarchy is to serve the purposes of the lower layers.<br /> loc. 1512</li>
<li>We know a tremendous amount about how the world works, but not nearly enough. Our knowledge is amazing; our ignorance even more so.<br /> loc. 1535</li>
<li><strong>You can’t navigate well in an interconnected, feedback-dominated world unless you take your eyes off short-term events and look for long term behavior and structure; unless you are aware of false boundaries and bounded rationality; unless you take into account limiting factors, nonlinearities and delays.</strong> <br /> loc. 1542 <strong>note:</strong> !!!</li>
<li><strong>Systems fool us by presenting themselves—or we fool ourselves by seeing the world—as a series of events.</strong> <br /> loc. 1561</li>
<li>Like the tip of an iceberg rising above the water, events are the most visible aspect of a larger complex—but not always the most important.<br /> loc. 1568</li>
<li>We are less likely to be surprised if we can see how events accumulate into dynamic patterns of behavior.<br /> loc. 1570</li>
<li>The behavior of a system is its performance over time—its growth, stagnation, decline, oscillation, randomness, or evolution.<br /> loc. 1573</li>
<li>structure is the key to understanding not just what is happening, but why.<br /> loc. 1577</li>
<li>The structure of a system is its interlocking stocks, flows, and feedback loops.<br /> loc. 1578</li>
<li>Structure determines what behaviors are latent in the system.<br /> loc. 1579</li>
<li>System structure is the source of system behavior. System behavior reveals itself as a series of events over time.<br /> loc. 1583</li>
<li>There’s no reason to expect any flow to bear a stable relationship to any other flow. Flows go up and down, on and off, in all sorts of combinations, in response to stocks, not to other flows.<br /> loc. 1603</li>
<li><strong>And that’s one reason why systems of all kinds surprise us. We are too fascinated by the events they generate. We pay too little attention to their history. And we are insufficiently skilled at seeing in their history clues to the structures from which behavior and events flow.</strong> <br /> loc. 1615 <strong>note:</strong> keep this is mind</li>
<li>A linear relationship between two elements in a system can be drawn on a graph with a straight line.<br /> loc. 1625</li>
<li>A nonlinear relationship is one in which the cause does not produce a proportional effect.<br /> loc. 1628</li>
<li>Nonlinearities are important not only because they confound our expectations about the relationship between action and response. They are even more important because they change the relative strengths of feedback loops.<br /> loc. 1647</li>
<li>Many relationships in systems are nonlinear. Their relative strengths shift in disproportionate amounts as the stocks in the system shift. Nonlinearities in feedback systems produce shifting dominance of loops and many complexities in system behavior.<br /> loc. 1688</li>
<li><strong>Everything, as they say, is connected to everything else, and not neatly. There is no clearly determinable boundary between the sea and the land, between sociology and anthropology, between an automobile’s exhaust and your nose. There are only boundaries of word, thought, perception, and social agreement—artificial, mental-model boundaries.</strong> <br /> loc. 1707</li>
<li>The greatest complexities arise exactly at boundaries.<br /> loc. 1710</li>
<li>If we’re to understand anything, we have to simplify, which means we have to make boundaries.<br /> loc. 1738</li>
<li>There is no single, legitimate boundary to draw around a system.<br /> loc. 1745</li>
<li>We have to invent boundaries for clarity and sanity; and boundaries can produce problems when we forget that we’ve artificially created them.<br /> loc. 1746</li>
<li>There are no separate systems. The world is a continuum. Where to draw a boundary around a system depends on the purpose of the discussion—the questions we want to ask.<br /> loc. 1747</li>
<li>you have to think about a boundary wider than the official perimeter.<br /> loc. 1758</li>
<li>boundaries are of our own making, and that they can and should be reconsidered for each new discussion, problem, or purpose.<br /> loc. 1780</li>
<li>Justus von Liebig came up with his famous “law of the minimum.”<br /> loc. 1813</li>
<li>At any given time, the input that is most important to a system is the one that is most limiting.<br /> loc. 1822</li>
<li>Rich countries transfer capital or technology to poor ones and wonder why the economies of the receiving countries still don’t develop, never thinking that capital or technology may not be the most limiting factors.<br /> loc. 1823</li>
<li><strong>There are layers of limits around every growing plant, child, epidemic, new product, technological advance, company, city, economy, and population. Insight comes not only from recognizing which factor is limiting, but from seeing that growth itself depletes or enhances limits and therefore changes what is limiting.</strong> <br /> loc. 1836</li>
<li>Whenever one factor ceases to be limiting, growth occurs, and the growth itself changes the relative scarcity of factors until another becomes limiting.<br /> loc. 1839</li>
<li>Any physical entity with multiple inputs and outputs is surrounded by layers of limits.<br /> loc. 1851</li>
<li>Changing the length of a delay may utterly change behavior. Delays are often sensitive leverage points for policy, if they can be made shorter or longer. You can see why that is. If a decision point in a system (or a person working in that part of the system) is responding to delayed information, or responding with a delay, the decisions will be off target.<br /> loc. 1888 <strong>note:</strong> social media advantage?</li>
<li>if action is taken too fast, it may nervously amplify short-term variation and create unnecessary instability.<br /> loc. 1891</li>
<li>Overshoots, oscillations, and collapses are always caused by delays.<br /> loc. 1893</li>
<li>When there are long delays in feedback loops, some sort of foresight is essential. To act only when a problem becomes obvious is to miss an important opportunity to solve the problem.<br /> loc. 1900 <strong>note:</strong> this is the point of my studies/interests</li>
<li>Bounded rationality means that people make quite reasonable decisions based on the information they have.<br /> loc. 1920</li>
<li><strong>We live in an exaggerated present—we pay too much attention to recent experience and too little attention to the past, focusing on current events rather than long term behavior.</strong> <br /> loc. 1934 <strong>note:</strong> modified concept of songgaar burungaar?</li>
<li>Blaming the individual rarely helps create a more desirable outcome.<br /> loc. 1965</li>
<li>Change comes first from stepping outside the limited information that can be seen from any single place in the system and getting an overview. From a wider perspective, information flows, goals, incentives, and disincentives can be restructured so that separate, bounded, rational actions do add up to results that everyone desires.<br /> loc. 1966 <strong>note:</strong> how do i do this with my thesis?</li>
<li>What makes a difference is redesigning the system to improve the information, incentives, disincentives, goals, stresses, and constraints that have an effect on specific actors.<br /> loc. 1997</li>
<li>The bounded rationality of each actor in a system may not lead to decisions that further the welfare of the system as a whole.<br /> loc. 1999</li>
<li>Boundaries are problem-dependent, evanescent, and messy; they are also necessary for organization and clarity. Being less surprised by complex systems is mainly a matter of learning to expect, appreciate, and use the world’s complexity.<br /> loc. 2012</li>
<li>Understanding archetypal problem-generating structures is not enough. Putting up with them is impossible. They need to be changed. The destruction they cause is often blamed on particular actors or events, although it is actually a consequence of system structure. Blaming, disciplining, firing, twisting policy levers harder, hoping for a more favorable sequence of driving events, tinkering at the margins—these standard responses will not fix structural problems.<br /> loc. 2019</li>
<li>Balancing loops stabilize systems; behavior patterns persist.<br /> loc. 2034</li>
<li><strong>Such resistance to change arises when goals of subsystems are different from and inconsistent with each other.</strong> <br /> loc. 2046</li>
<li>ratchet mode: Intensification of anyone’s effort leads to intensification of everyone else’s.<br /> loc. 2057</li>
<li>Harmonization of goals in a system is not always possible, but it’s an worth looking for. It can be found only by letting go of more narrow goals and considering the long term welfare of the entire system.<br /> loc. 2098</li>
<li>When various actors try to pull a system stock toward various goals, the result can be policy resistance. Any new policy, especially if it’s effective, just pulls the stock farther from the goals of other actors and produces additional resistance, with a result that no one likes, but that everyone expends considerable effort in maintaining.<br /> loc. 2102</li>
<li><strong>The trap called the tragedy of the commons comes about when there is escalation, or just simple growth, in a commonly shared, erodable environment.</strong> <br /> loc. 2113</li>
<li>Therein is the tragedy. Each . . . is locked into a system that compels him to increase his herd without limit—in a world that is limited. Ruin is the destination toward which all . . . rush, each pursuing his own best interest.<br /> loc. 2123</li>
<li>The tragedy of the commons arises from missing (or too long delayed) feedback from the resource to the growth of the users of that resource.<br /> loc. 2137</li>
<li>Tragedy can lurk not only in the use of common resources, but also in the use of common sinks, shared places where pollution can be dumped.<br /> loc. 2153</li>
<li>The structure of a commons system makes selfish behavior much more convenient and profitable than behavior that is responsible to the whole community and to the future.<br /> loc. 2159</li>
<li>If your freedom to broadcast were not limited, the airwaves would be a chaos of overlapping signals.<br /> loc. 2192 <strong>note:</strong> is that whqt we&#39;re experiencing now?</li>
<li>When there is a commonly shared resource, every user benefits directly from its use, but shares the costs of its abuse with everyone else. Therefore, there is very weak feedback from the condition of the resource to the decisions of the resource users. The consequence is overuse of the resource, eroding it until it becomes unavailable to anyone.<br /> loc. 2203</li>
<li>Escalation comes from a reinforcing loop set up by competing actors trying to get ahead of each other.<br /> loc. 2265</li>
<li>Escalation, being a reinforcing feedback loop, builds exponentially. Therefore, it can carry a competition to extremes faster than anyone would believe possible. If nothing is done to break the loop, the process usually ends with one or both of the competitors breaking down.<br /> loc. 2292 <strong>note:</strong> escalation in social conflict</li>
<li>When the state of one stock is determined by trying to surpass the state of another stock—and vice versa—then there is a reinforcing feedback loop carrying the system into an arms race, a wealth race, a smear campaign, escalating loudness, escalating violence. The escalation is exponential and can lead to extremes surprisingly quickly. If nothing is done, the spiral will be stopped by someone’s collapse—because exponential growth cannot go on forever.<br /> loc. 2303</li>
<li>These equalizing mechanisms may derive from simple morality, or they may come from the practical understanding that losers, if they are unable to get out of the game of success to the successful, and if they have no hope of winning, could get frustrated enough to destroy the playing field.<br /> loc. 2379</li>
<li>Rule beating is usually a response of the lower levels in a hierarchy to overrigid, deleterious, unworkable, or ill-defined rules from above.<br /> loc. 2517</li>
<li>the opportunity, is to understand rule beating as useful feedback, and to revise, improve, rescind, or better explain the rules.<br /> loc. 2521</li>
<li>the goal is the direction-setter of the system, the definer of discrepancies that require action, the indicator of compliance, failure, or success toward which balancing feedback loops work. If the goal is defined badly, if it doesn’t measure what it’s supposed to measure, if it doesn’t reflect the real welfare of the system, then the system can’t possibly produce a desirable result. Systems, like the three wishes in the traditional fairy tale, have a terrible tendency to produce exactly and only what you ask them to produce. Be careful what you ask them to produce.<br /> loc. 2538 <strong>note:</strong> consider this during thesis-writing</li>
<li>System behavior is particularly sensitive to the goals of feedback loops. If the goals—the indicators of satisfaction of the rules—are defined inaccurately or incompletely, the system may obediently work to produce a result that is not really intended or wanted.<br /> loc. 2584</li>
<li>Leverage points are points of power.<br /> loc. 2622</li>
<li>Counterintuitive—that’s Forrester’s word to describe complex systems. Leverage points frequently are not intuitive. Or if they are, we too often use them backward, systematically worsening whatever problems we are trying to solve.<br /> loc. 2637</li>
<li>I have come up with no quick or easy formulas for finding leverage points in complex and dynamic systems. Give me a few months or years and I’ll figure it out. And I know from bitter experience that, because they are so counterintuitive, when I do discover a system’s leverage points, hardly anybody will believe me. Very frustrating—especially for those of us who yearn not just to understand complex systems, but to make the world work better.<br /> loc. 2640 <strong>note:</strong> note to self</li>
<li>Numbers, the sizes of flows, are dead last on my list of powerful interventions. Diddling with the details, arranging the deck chairs on the Titanic. Probably 90—no 95, no 99 percent—of our attention goes to parameters, but there’s not a lot of leverage in them.<br /> loc. 2674</li>
<li>Parameters become leverage points when they go into ranges that kick off one of the items higher on this list. Interest rates, for example, or birth rates, control the gains around reinforcing feedback loops. System goals are parameters that can make big differences.<br /> loc. 2685</li>
<li>a big, stabilizing stock is known as a buffer.<br /> loc. 2704</li>
<li>You can often stabilize a system by increasing the capacity of a buffer.5 But if a buffer is too big, the system gets inflexible. It reacts too slowly.<br /> loc. 2709</li>
<li>The only way to fix a system that is laid out poorly is to rebuild it, if you can.<br /> loc. 2721</li>
<li>Physical structure is crucial in a system, but is rarely a leverage point, because changing it is rarely quick or simple. The leverage point is in proper design in the first place. After the structure is built, the leverage is in understanding its limitations and bottlenecks, using it with maximum efficiency, and refraining from fluctuations or expansions that strain its capacity.<br /> loc. 2729</li>
<li>A delay in a feedback process is critical relative to rates of change in the stocks that the feedback loop is trying to control. Delays that are too short cause overreaction, “chasing your tail,” oscillations amplified by the jumpiness of the response. Delays that are too long cause damped, sustained, or exploding oscillations, depending on how much too long. Overlong delays in a system with a threshold, a danger point, a range past which irreversible damage can occur, cause overshoot and collapse.<br /> loc. 2745</li>
<li>It’s usually easier to slow down the change rate, so that inevitable feedback delays won’t cause so much trouble.<br /> loc. 2751</li>
<li>And that’s why slowing economic growth is a greater leverage point in Forrester’s World model than faster technological development or freer market prices. Those are attempts to speed up the rate of adjustment. But the world’s physical capital stock, its factories and boilers, the concrete manifestations of its working technologies, can change only so fast, even in the face of new prices or new ideas—and prices and ideas don’t change instantly either, not through a whole global culture. There’s more leverage in slowing the system down so technologies and prices can keep up with it, than there is in wishing the delays would go away.<br /> loc. 2753 <strong>note:</strong> critical concept for my paper</li>
<li>Balancing feedback loops are ubiquitous in systems. Nature evolves them and humans invent them as controls to keep important stocks within safe bounds.<br /> loc. 2763</li>
<li>The strength of a balancing feedback loop is important relative to the impact it is designed to correct<br /> loc. 2792</li>
<li><strong>Democracy works better without the brainwashing power of centralized mass communications.</strong> <br /> loc. 2795</li>
<li>Reinforcing feedback loops are sources of growth, explosion, erosion, and collapse in systems. A system with an unchecked reinforcing loop ultimately will destroy itself.<br /> loc. 2813</li>
<li>Missing information flows is one of the most common causes of system malfunction.<br /> loc. 2841</li>
<li>Adding or restoring information can be a powerful intervention, usually much easier and cheaper than rebuilding physical infrastructure.<br /> loc. 2841</li>
<li>There is a systematic tendency on the part of human beings to avoid accountability for their own decisions.<br /> loc. 2855</li>
<li>what our behavior would be under them, we come to understand the power of rules. They are high leverage points. Power over the rules is real power.<br /> loc. 2870</li>
<li><strong>If you want to understand the deepest malfunctions of systems, pay attention to the rules and to who has power over them.</strong> <br /> loc. 2873</li>
<li>The most stunning thing living systems and some social systems can do is to change themselves utterly by creating whole new structures and behaviors.<br /> loc. 2881</li>
<li><strong>The ability to self-organize is the strongest form of system resilience.</strong> <br /> loc. 2885</li>
<li>one aspect of almost every culture is the belief in the utter superiority of that culture.<br /> loc. 2911</li>
<li>If the goal is to bring more and more of the world under the control of one particular central planning system (the empire of Genghis Khan, the Church, the People’s Republic of China, Wal-Mart, Disney), then everything further down the list, physical stocks and flows, feedback loops, information flows, even self-organizing behavior, will be twisted to conform to that goal.<br /> loc. 2920</li>
<li>The shared idea in the minds of society, the great big unstated assumptions, constitute that society’s paradigm, or deepest set of beliefs about how the world works.<br /> loc. 2954</li>
<li>Paradigms are the sources of systems. From them, from shared social agreements about the nature of reality, come system goals and information flows, feedbacks, stocks, flows, and everything else about systems.<br /> loc. 2960</li>
<li>people who have managed to intervene in systems at the level of paradigm have hit a leverage point that totally transforms systems.<br /> loc. 2971</li>
<li><strong>no paradigm is “true,” that every one, including the one that sweetly shapes your own worldview, is a tremendously limited understanding of an immense and amazing universe that is far beyond human comprehension.</strong> <br /> loc. 2984</li>
<li>The higher the leverage point, the more the system will resist changing it—that’s why societies often rub out truly enlightened beings.** <br /> loc. 2998</li>
<li>mastery has less to do with pushing leverage points than it does with strategically, profoundly, madly, letting go and dancing with the system.<br /> loc. 3002</li>
<li>it’s one thing to under stand how to fix a system and quite another to wade in and fix it.<br /> loc. 3022</li>
<li><strong>Social systems are the external manifestations of cultural thinking patterns and of profound human needs, emotions, strengths, and weaknesses. Changing them is not as simple as saying “now all change,” or of trusting that he who knows the good shall do the good.</strong> <br /> loc. 3027 <strong>note:</strong> very pertinent</li>
<li>Systems thinking makes clear even to the most committed technocrat that getting along in this world of complex systems requires more than technocracy.<br /> loc. 3039</li>
<li>Starting with the behavior of the system forces you to focus on facts, not theories. It keeps you from falling too quickly into your own beliefs or misconceptions, or those of others.<br /> loc. 3096</li>
<li><strong>Starting with the history of several variables plotted together begins to suggest not only what elements are in the system, but how they might be interconnected.</strong> <br /> loc. 3108</li>
<li>Instead of becoming a champion for one possible explanation or hypothesis or model, collect as many as possible.<br /> loc. 3127</li>
<li>Information is power. Anyone interested in power grasps that idea very quickly. The media, the public relations people, the politicians, and advertisers who regulate much of the public flow of information have far more power than most people realize. They filter and channel information. Often they do so for short-term, self-interested purposes.<br /> loc. 3148</li>
<li>Attention rests upon percentages, categories, abstract functions. . . . It is not language that the user will very likely be required to stand by or to act on, for it does not define any personal ground for standing or acting.<br /> loc. 3173 <strong>note:</strong> backup for dissertation</li>
<li>Our culture, obsessed with numbers, has given us the idea that what we can measure is more important than what we can’t measure.<br /> loc. 3187</li>
<li>Pretending that something doesn’t exist if it’s hard to quantify leads to faulty models.<br /> loc. 3203</li>
<li>Don’t be an unthinking intervenor and destroy the system’s own self-maintenance capacities. Before you charge in to make things better, pay attention to the value of what’s already there.<br /> loc. 3239</li>
<li>Do pay attention to the triggering events, the outside influences that bring forth one kind of behavior from the system rather than another.<br /> loc. 3250</li>
<li>Warfare became even more irresponsible when it became possible to push a button and cause tremendous damage at such a distance that the person pushing the button never even sees the damage.<br /> loc. 3269</li>
<li>The thing to do, when you don’t know, is not to bluff and not to freeze, but to learn.<br /> loc. 3279</li>
<li>The official time horizon of industrial society doesn’t extend beyond what will happen after the next election or beyond the payback period of current investments.<br /> loc. 3313</li>
<li>The longer the operant time horizon, the better the chances for survival.<br /> loc. 3316</li>
<li><strong>We experience now the consequences of actions set in motion yesterday and decades ago and centuries ago.</strong> <br /> loc. 3324</li>
</ul>

</div>
</body>

        <div class="container">
          
<!-- Add Disqus comments. -->
<div id="disqus_thread"></div>
<script type="text/javascript">
  /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
  var disqus_shortname = 'elisabethgray'; // required: replace example with your forum shortname
  var disqus_identifier = "/projects/arab-uprisings/notes/thinking-in-systems/";

  /* * * DON'T EDIT BELOW THIS LINE * * */
  (function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>


        </div>
        <hr>
          <center>
  <h6>
    <span xmlns:dct="http://purl.org/dc/terms/" property="dct:title">Personal and academic work</span> by <a xmlns:cc="http://creativecommons.org/ns#" href="http://elisabethgray.me/" property="cc:attributionName" rel="cc:attributionURL">Elisabeth Gray</a> is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.
  </h6>
</center>

        <br />
        <br />
      </div>
    </div>
  </body>

</html>
